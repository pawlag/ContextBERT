# ContextualBERT-pytorch

<<<<<<< HEAD
Pytorch implementation of BERT model with additional context input

> BERT 2018 BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
> Paper URL: https://arxiv.org/abs/1810.04805


=======
Pytorch implementation of BERT model with context input.

> BERT 2018 BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
> Paper URL: https://arxiv.org/abs/1810.04805
> 
>>>>>>> 16e8b401c1971295e4af0a748fdf9414b290acd1
> Contextual BERT:  Conditioning the Language Model Using a Global State
> Paper URL: https://arxiv.org/abs/2010.15778


## Introduction

...


## Author
Pawel Lagodzinski  (pawel.lagodzinski@gmail.com)

## License

This project following Apache 2.0 License as written in LICENSE file

Copyright (c) 2018 Junseong Kim, Scatter Lab, respective BERT contributors

Copyright (c) 2018 Alexander Rush : [The Annotated Trasnformer](https://github.com/harvardnlp/annotated-transformer)
